{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCgt_lqGW-Hi"
      },
      "source": [
        "# BoltzDesign1 âš¡âœ¨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x9oNgLeUfBb"
      },
      "source": [
        "For more details, read BoltzDesign1 paper **(https://www.biorxiv.org/content/10.1101/2025.04.06.647261v1)**\n",
        "\n",
        "**â— WARNING:** the following pipeline is in active development and has NOT been experimentally validated in lab. We are releasing the code to allow the community to contribute and build on.\n",
        "\n",
        "**ğŸ“§ Contact**\n",
        "For feedback, questions or collaboration opportunities, please email yehlin@mit.edu\n",
        "\n",
        "**â¡ï¸ Reference**\n",
        "We implemented the visualization of designing trajectories using logMD (https://colab.research.google.com/drive/1-9GXUPna4T0VFlDz9I64gzRQz259_G8f?usp=sharing#scrollTo=4eXNO1JJHYrB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VRy8gghY53N",
        "outputId": "0708a90d-40f5-4805-fe0f-2a65c25df40f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BoltzDesign1'...\n",
            "remote: Enumerating objects: 475, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 475 (delta 79), reused 67 (delta 64), pack-reused 377 (from 1)\u001b[K\n",
            "Receiving objects: 100% (475/475), 492.06 KiB | 9.28 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n",
            "Collecting git+https://github.com/prody/ProDy.git\n",
            "  Cloning https://github.com/prody/ProDy.git to /tmp/pip-req-build-gtr0kc94\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/prody/ProDy.git /tmp/pip-req-build-gtr0kc94\n",
            "  Resolved https://github.com/prody/ProDy.git to commit 4d75baaa769fd7a0173cfe18ea208bb6fb76bdcc\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Processing /content/BoltzDesign1/boltz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<2,>=1.10 (from ProDy==2.5.0)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting biopython (from ProDy==2.5.0)\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting pyparsing<=3.1.1 (from ProDy==2.5.0)\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ProDy==2.5.0) (1.15.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ProDy==2.5.0) (75.2.0)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from boltz==0.4.1) (2.6.0+cu124)\n",
            "Collecting numpy<2,>=1.10 (from ProDy==2.5.0)\n",
            "  Downloading numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core==1.3.2 (from boltz==0.4.1)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting pytorch-lightning==2.4.0 (from boltz==0.4.1)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting rdkit>=2024.3.2 (from boltz==0.4.1)\n",
            "  Downloading rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting dm-tree==0.1.8 (from boltz==0.4.1)\n",
            "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from boltz==0.4.1) (2.32.3)\n",
            "Requirement already satisfied: pandas>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from boltz==0.4.1) (2.2.2)\n",
            "Collecting types-requests (from boltz==0.4.1)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting einops==0.8.0 (from boltz==0.4.1)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting einx==0.3.0 (from boltz==0.4.1)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fairscale==0.4.13 (from boltz==0.4.1)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mashumaro==3.14 (from boltz==0.4.1)\n",
            "  Downloading mashumaro-3.14-py3-none-any.whl.metadata (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.4/114.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting modelcif==1.2 (from boltz==0.4.1)\n",
            "  Downloading modelcif-1.2.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb==0.18.7 (from boltz==0.4.1)\n",
            "  Downloading wandb-0.18.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting click==8.1.7 (from boltz==0.4.1)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyyaml==6.0.2 in /usr/local/lib/python3.11/dist-packages (from boltz==0.4.1) (6.0.2)\n",
            "Collecting biopython (from ProDy==2.5.0)\n",
            "  Downloading biopython-1.84-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting scipy (from ProDy==2.5.0)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from einx==0.3.0->boltz==0.4.1) (1.13.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx==0.3.0->boltz==0.4.1) (2.4.6)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core==1.3.2->boltz==0.4.1) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core==1.3.2->boltz==0.4.1) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core==1.3.2->boltz==0.4.1) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from mashumaro==3.14->boltz==0.4.1) (4.14.0)\n",
            "Collecting ihm>=1.7 (from modelcif==1.2->boltz==0.4.1)\n",
            "  Downloading ihm-2.6.tar.gz (391 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m391.5/391.5 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.4.0->boltz==0.4.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==2.4.0->boltz==0.4.1)\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning==2.4.0->boltz==0.4.1)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->boltz==0.4.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->boltz==0.4.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->boltz==0.4.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3->boltz==0.4.1) (2025.4.26)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.18.7->boltz==0.4.1) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.18.7->boltz==0.4.1) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb==0.18.7->boltz==0.4.1) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.18.7->boltz==0.4.1) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.18.7->boltz==0.4.1) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.18.7->boltz==0.4.1) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb==0.18.7->boltz==0.4.1) (1.3.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->boltz==0.4.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->boltz==0.4.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->boltz==0.4.1) (2025.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit>=2024.3.2->boltz==0.4.1) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->boltz==0.4.1) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->boltz==0.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->boltz==0.4.1) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->boltz==0.4.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->boltz==0.4.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->boltz==0.4.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.2->boltz==0.4.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->boltz==0.4.1) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->einx==0.3.0->boltz==0.4.1) (1.3.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb==0.18.7->boltz==0.4.1) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (3.11.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.18.7->boltz==0.4.1) (4.0.12)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from ihm>=1.7->modelcif==1.2->boltz==0.4.1) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->boltz==0.4.1) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.4.0->boltz==0.4.1) (1.20.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.18.7->boltz==0.4.1) (5.0.2)\n",
            "Downloading biopython-1.84-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mashumaro-3.14-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.18.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "Downloading rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl (34.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ProDy, boltz, fairscale, modelcif, ihm\n",
            "  Building wheel for ProDy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ProDy: filename=prody-2.5.0-cp311-cp311-linux_x86_64.whl size=25950192 sha256=ea78640e6e8a449e81d92bb4a66ddd5f869c1509a40ce0b9626bee63de633c7d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bu7xc2rv/wheels/63/93/43/0a3638297255fa4eafaccffee89b60135edb3f220faaf09d25\n",
            "  Building wheel for boltz (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boltz: filename=boltz-0.4.1-py3-none-any.whl size=147706 sha256=d934c1840b928388123b17a5dfb84d32e72db5bff7a18d6647c4d7a7c5500c40\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bu7xc2rv/wheels/43/cc/79/c293bfa4c37065582037c01d0bc0c4b7b3d2be0d115b0c9da9\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332208 sha256=36fd8b698280a9587350716b5d605487ac6e6eb0a01168bce919bde609f0d102\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/ef/96/5044bde220b2ea299bdc6ec05051e0ef187fad45b341d1c273\n",
            "  Building wheel for modelcif (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for modelcif: filename=modelcif-1.2-py3-none-any.whl size=41180 sha256=59333c45edc8cc0551a2320d8bb846b57f3c72bb0dcc98583155eac7b8abc960\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/3a/8c/e28cb28a15568d1b1b6163c77c945a5961351340fd15b9b4df\n",
            "  Building wheel for ihm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ihm: filename=ihm-2.6-cp311-cp311-linux_x86_64.whl size=384330 sha256=0b29e62f3ff759aa10063fa9e4a9a951409bc9c2a68065663736beb2b6454dd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/ab/8a/ea4813c16ab65a7faeee2ef4dd34d4f18e996e134be20dff37\n",
            "Successfully built ProDy boltz fairscale modelcif ihm\n",
            "Installing collected packages: dm-tree, types-requests, pyparsing, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mashumaro, lightning-utilities, ihm, einops, click, scipy, rdkit, nvidia-cusparse-cu12, nvidia-cudnn-cu12, modelcif, hydra-core, einx, biopython, wandb, ProDy, nvidia-cusolver-cu12, torchmetrics, fairscale, pytorch-lightning, boltz\n",
            "  Attempting uninstall: dm-tree\n",
            "    Found existing installation: dm-tree 0.1.9\n",
            "    Uninstalling dm-tree-0.1.9:\n",
            "      Successfully uninstalled dm-tree-0.1.9\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.19.11\n",
            "    Uninstalling wandb-0.19.11:\n",
            "      Successfully uninstalled wandb-0.19.11\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ProDy-2.5.0 biopython-1.84 boltz-0.4.1 click-8.1.7 dm-tree-0.1.8 einops-0.8.0 einx-0.3.0 fairscale-0.4.13 hydra-core-1.3.2 ihm-2.6 lightning-utilities-0.14.3 mashumaro-3.14 modelcif-1.2 numpy-1.26.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyparsing-3.1.1 pytorch-lightning-2.4.0 rdkit-2025.3.3 scipy-1.13.1 torchmetrics-1.7.3 types-requests-2.32.4.20250611 wandb-0.18.7\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCPU times: user 5.58 s, sys: 1.54 s, total: 7.12 s\n",
            "Wall time: 3min 59s\n"
          ]
        }
      ],
      "source": [
        "#@title ğŸ› ï¸ setup (~3 minutes)\n",
        "%%time\n",
        "import os, time, gc, io\n",
        "import contextlib\n",
        "from pathlib import Path\n",
        "\n",
        "if not os.path.isdir(\"BoltzDesign1\"):\n",
        "  !git clone https://github.com/yehlincho/BoltzDesign1.git\n",
        "  !cd /content/BoltzDesign1/boltz; pip install git+https://github.com/prody/ProDy.git .\n",
        "  !pip install pypdb -qqq\n",
        "  !pip install py3Dmol -qqq\n",
        "  !pip install logmd -qqq\n",
        "  !cd /content/BoltzDesign1/LigandMPNN && bash get_model_params.sh \"./model_params\"\n",
        "  exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GcBLe2CsEz3s",
        "outputId": "1ad62fd2-ccee-4135-a71b-9b47906447c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the CCD dictionary to ccd.pkl. You may change the cache directory with the --cache flag.\n",
            "Downloading the model weights to boltz1_conf.ckpt. You may change the cache directory with the --cache flag.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "@> ProDy is configured: verbosity='none'\n",
            "INFO:.prody:ProDy is configured: verbosity='none'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded model\n"
          ]
        }
      ],
      "source": [
        "#@title ğŸ› ï¸ load models\n",
        "from boltz.main import download\n",
        "from pathlib import Path\n",
        "download(Path(\".\"))\n",
        "\n",
        "import os, sys\n",
        "sys.path.append('./BoltzDesign1/boltzdesign')\n",
        "from boltzdesign_utils import *\n",
        "from ligandmpnn_utils import *\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "ccd_path = \"ccd.pkl\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "predict_args = {\n",
        "    \"recycling_steps\": 0,  # Default value\n",
        "    \"sampling_steps\": 200,  # Default value\n",
        "    \"diffusion_samples\": 1,  # Default value\n",
        "    \"write_confidence_summary\": True,\n",
        "    \"write_full_pae\": False,\n",
        "    \"write_full_pde\": False,\n",
        "}\n",
        "\n",
        "boltz_model = get_boltz_model('boltz1_conf.ckpt', predict_args, device)\n",
        "boltz_model.train()\n",
        "print(\"loaded model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "imUeHSGnxUnp"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ› ï¸ load utils\n",
        "from input_utils import *\n",
        "from utils import *\n",
        "\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "from prody import parsePDB\n",
        "import pypdb\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def generate_yaml_config(\n",
        "    input_type,\n",
        "    pdb_path,\n",
        "    target_type,\n",
        "    target_name,\n",
        "    pdb_target_ids,\n",
        "    target_mols,\n",
        "    custom_target_input,\n",
        "    custom_target_ids,\n",
        "    binder_id,\n",
        "    use_msa,\n",
        "    contact_residues,\n",
        "    modifications,\n",
        "    modifications_positions,\n",
        "    modification_target,\n",
        "    constraint_target,\n",
        "    config_obj\n",
        "):\n",
        "    \"\"\"Generate YAML configuration based on input type\"\"\"\n",
        "    # Process constraints if specified\n",
        "    constraints = None\n",
        "    modifications_dict = None\n",
        "    if contact_residues or modifications:\n",
        "        target_ids = pdb_target_ids if input_type == \"pdb\" else custom_target_ids\n",
        "        target_ids_list = [str(x.strip()) for x in target_ids.split(\",\")] if target_ids else []\n",
        "        target_id_map = {id: c for id, c in zip(target_ids_list, 'BCDEFGHIJKLMNOPQRSTUVWXYZ')}\n",
        "        print(f\"Mapped target IDs: {list(target_id_map.values())}\")\n",
        "        constraints, modifications_dict = process_design_constraints(\n",
        "            target_id_map, modifications, modifications_positions,\n",
        "            modification_target, contact_residues, constraint_target, binder_id\n",
        "        )\n",
        "\n",
        "    # Get target sequences\n",
        "    target = []\n",
        "    if input_type == \"pdb\":\n",
        "        if pdb_path is not None:\n",
        "            print(\"load local pdb from\", pdb_path)\n",
        "            if not Path(pdb_path).is_file():\n",
        "                raise FileNotFoundError(f\"Could not find local PDB: {pdb_path}\")\n",
        "        else:\n",
        "            print(\"download pdb from RCSB\")\n",
        "            download_pdb(target_name, config_obj.PDB_DIR)\n",
        "            pdb_path = config_obj.PDB_DIR / f\"{target_name}.pdb\"\n",
        "\n",
        "        if target_type in ['rna', 'dna']:\n",
        "            nucleotides = get_nucleotide_from_pdb(pdb_path)\n",
        "            target = [nucleotides[id]['seq'] for id in pdb_target_ids.split(\",\")]\n",
        "        elif target_type == 'small_molecule':\n",
        "            ligands = get_ligand_from_pdb(target_name)\n",
        "            target = [ligands[mol] for mol in target_mols.split(\",\")]\n",
        "        elif target_type == 'protein':\n",
        "            sequences = get_chains_sequence(pdb_path)\n",
        "            target = [sequences[id] for id in pdb_target_ids.split(\",\")]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported target type: {target_type}\")\n",
        "    else:\n",
        "        target = custom_target_input.split(\",\") if custom_target_input else [target_name]\n",
        "\n",
        "    return generate_yaml_for_target_binder(\n",
        "        target_name,\n",
        "        target_type,\n",
        "        target,\n",
        "        config=config_obj,\n",
        "        binder_id=binder_id,\n",
        "        constraints=constraints,\n",
        "        modifications=modifications_dict['data'] if modifications_dict else None,\n",
        "        modification_target=modifications_dict['target'] if modifications_dict else None,\n",
        "        use_msa=use_msa\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "OqhTVwJNlSbK",
        "outputId": "76fe15cd-a1a2-4852-a8e7-4062da24c273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:.prody:Connecting wwPDB FTP server RCSB PDB (USA).\n",
            "INFO:.prody:Downloading PDB files via FTP failed, trying HTTP.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load local pdb from /content/BoltzDesign1/inputs/7v11.pdb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:.prody:7v11 downloaded (7v11.pdb.gz)\n",
            "DEBUG:.prody:PDB download via HTTP completed (1 downloaded, 0 failed).\n",
            "DEBUG:.prody:2139 atoms and 1 coordinate set(s) were parsed in 0.03s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated YAML configuration:\n",
            "version:\n",
            "  1\n",
            "sequences:\n",
            "  - {'protein': {'id': ['A'], 'sequence': 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX', 'msa': 'empty'}}\n",
            "  - {'ligand': {'id': ['B'], 'smiles': 'Fc1c(Cl)ccc(n2cnnn2)c1c1c[n+]([O-])c(cc1)C(CC1CC1)n1cc(cn1)c1ccc(N)nc1C'}}\n",
            "\n",
            "ğŸ¯ target_type: small_molecule\n",
            "ğŸ“‚ Using config path: /content/BoltzDesign1/boltzdesign/configs/default_sm_config.yaml\n",
            "\n",
            "ğŸ’¾ YAML config saved at: /content/inputs/test_data/7v11_binder/yaml/7v11.yaml\n",
            "ğŸ¨ Design outputs will be saved in: outputs\n",
            "CPU times: user 74.4 ms, sys: 6.12 ms, total: 80.5 ms\n",
            "Wall time: 1.85 s\n"
          ]
        }
      ],
      "source": [
        "#@title ğŸ“„ Generate YAML file for protein design\n",
        "\n",
        "%%time\n",
        "import warnings, os, re\n",
        "import yaml\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "# USER OPTIONS\n",
        "\n",
        "#@markdown Select input type:\n",
        "input_type = \"pdb\" #@param [\"pdb\", \"custom\"]\n",
        "#@markdown Specify custom pdb path, otherwise will fetch from RCSB\n",
        "pdb_path = \"/content/BoltzDesign1/inputs/7v11.pdb\" #@param {type:\"string\"}\n",
        "#@markdown Select target type:\n",
        "target_type = \"small_molecule\" #@param [\"protein\", \"rna\", \"dna\", \"small_molecule\", \"metal\"]\n",
        "non_protein_target = False if target_type == \"protein\" else True\n",
        "#@markdown Enter target name/PDB code:\n",
        "target_name = \"7v11\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown For PDB targets, protein and DNA/RNA enter target chain ID (optional), if multiple, comma-separated list(e.g. \"A, B\")\n",
        "pdb_target_ids = \"A\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown For PDB targets, small molecule enter target mol (optional), if multiple, comma-separated list(e.g. \"SAM, FAD\")\n",
        "target_mols = \"OQO\" #@param {type:\"string\"}\n",
        "#@markdown For custom input, enter target sequences/SMILES (comma-separated for multiple, (e.g. \"ATGC, TACG\")\n",
        "custom_target_input = \"\" #@param {type:\"string\"}\n",
        "#@markdown target ids (e.g. \"B\", \"C\")\n",
        "custom_target_ids = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter binder chain ID (default: A):\n",
        "binder_id = \"A\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Use MSA; if False, runs in single-sequence mode\n",
        "use_msa = False  #@param {type:\"boolean\"}\n",
        "#@markdown Enter msa max seqs (default: 4096):\n",
        "msa_max_seqs = 4096 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Add modifications? (comma-separated, e.g., \"SEP, SEP\")\n",
        "modifications = \"\" #@param {type:\"string\"}\n",
        "#@markdown Add modifications to which residues? (comma-separated, e.g., \"S, S\")\n",
        "modifications_wt = \"\" #@param {type:\"string\"}\n",
        "#@markdown Specify positions? (comma-separated, matching order, e.g., \"2,3\"\n",
        "modifications_positions = \"\" #@param {type:\"string\"}\n",
        "#@markdown Target ID for modifications (e.g., \"B\")\n",
        "modification_target = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Target ID for constraints (e.g., \"B\")\n",
        "constraint_target = \"\" #@param {type:\"string\"}\n",
        "#@markdown Specify positions? (Contact residues for constraints (comma-separated, e.g., \"99,100,109\")')\n",
        "contact_residues = \"\" #@param {type:\"string\"}\n",
        "\n",
        "pocket_conditioning =bool(contact_residues)\n",
        "\n",
        "config = Config(main_dir=f'/content/inputs/test_data/{target_name}_binder')\n",
        "config.setup_directories()\n",
        "\n",
        "yaml_dict, yaml_dir = generate_yaml_config(\n",
        "    input_type,\n",
        "    pdb_path,\n",
        "    target_type,\n",
        "    target_name,\n",
        "    pdb_target_ids,\n",
        "    target_mols,\n",
        "    custom_target_input,\n",
        "    custom_target_ids,\n",
        "    binder_id,\n",
        "    use_msa,\n",
        "    contact_residues,\n",
        "    modifications,\n",
        "    modifications_positions,\n",
        "    modification_target,\n",
        "    constraint_target,\n",
        "    config\n",
        ")\n",
        "\n",
        "print(\"Generated YAML configuration:\")\n",
        "for key, value in yaml_dict.items():\n",
        "    print(f\"{key}:\")\n",
        "    if isinstance(value, dict):\n",
        "        for k, v in value.items():\n",
        "            if isinstance(v, list):\n",
        "                print(f\"  {k}:\")\n",
        "                for item in v:\n",
        "                    print(f\"    - {item}\")\n",
        "            else:\n",
        "                print(f\"  {k}: {v}\")\n",
        "    elif isinstance(value, list):\n",
        "        for item in value:\n",
        "            print(f\"  - {item}\")\n",
        "    else:\n",
        "        print(f\"  {value}\")\n",
        "# Load initial config.yaml values\n",
        "\n",
        "print(\"\\nğŸ¯ target_type:\", target_type)\n",
        "if target_type == 'small_molecule':\n",
        "    config_path = \"/content/BoltzDesign1/boltzdesign/configs/default_sm_config.yaml\"\n",
        "elif target_type == 'metal':\n",
        "    config_path = \"/content/BoltzDesign1/boltzdesign/configs/default_metal_config.yaml\"\n",
        "elif target_type in ('dna', 'rna'):\n",
        "    config_path = \"/content/BoltzDesign1/boltzdesign/configs/default_na_config.yaml\"\n",
        "elif target_type == 'protein':\n",
        "    config_path = \"/content/BoltzDesign1/boltzdesign/configs/default_ppi_config.yaml\"\n",
        "\n",
        "print(\"ğŸ“‚ Using config path:\", config_path)\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "main_dir = 'outputs'\n",
        "os.makedirs(main_dir, exist_ok=True)\n",
        "version_name = f'{target_type}_{target_name}'\n",
        "print(f\"\\nğŸ’¾ YAML config saved at: {yaml_dir}\")\n",
        "print(f\"ğŸ¨ Design outputs will be saved in: {main_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SKVUTD4iNkA"
      },
      "source": [
        "## 2. Run BoltzDesign protocol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "FD5TWUt1TgWt"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ§¬ Protein design settings\n",
        "\n",
        "# Always update other shared parameters\n",
        "#@markdown Number of designs to generate\n",
        "design_samples = 1  #@param {type:\"integer\"}\n",
        "#@markdown Select minimum and maximum length (default min : 100, max: 150)\n",
        "length_min = 250  #@param {type:\"integer\"}\n",
        "length_max = 300  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Select optimizer (default: SGD)\n",
        "optimizer_type = \"SGD\"  #@param [\"SGD\", \"AdamW\"]\n",
        "\n",
        "config['binder_chain'] = binder_id\n",
        "config['non_protein_target'] = non_protein_target\n",
        "config['msa_max_seqs'] = msa_max_seqs\n",
        "config['length_min'] = length_min\n",
        "config['length_max'] = length_max\n",
        "config['optimizer_type'] = optimizer_type\n",
        "config['pocket_conditioning'] = pocket_conditioning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "llPt6bkYTVNb",
        "cellView": "form",
        "outputId": "03edb65b-99c8-4280-f460-2aef9d188275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ **Protein Design Settings**\n",
            "â„¹ï¸ Using default config; no updates applied.\n"
          ]
        }
      ],
      "source": [
        "#@title âš™ï¸ (Optional: Change protein design settings)\n",
        "\n",
        "# @markdown ğŸŒŸ **Use default config?** (if False, override with param you change)\n",
        "use_default_config = True  # @param {type:\"boolean\"}\n",
        "# @markdown ---\n",
        "print(\"\\nğŸ”§ **Protein Design Settings**\")\n",
        "\n",
        "# If user chooses to override, they can set these params below:\n",
        "# @markdown Mask target for warm-up stage\n",
        "mask_ligand = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Optimize interface contact per binder position\n",
        "# (default: False for small molecule and metal, True for protein and NA)\n",
        "optimize_contact_per_binder_pos = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Only use distogram for optimization (else use both pairformer and confidence modules)\n",
        "distogram_only = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Design algorithm\n",
        "design_algorithm = \"3stages\"  # @param [\"3stages\", \"3stages_extra\"]\n",
        "\n",
        "# @markdown Softmax temperature for 3stages (logits to softmax, T = e_soft)\n",
        "e_soft = 0.8  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Softmax temperature for 3stages_extra (Initial logits to softmax, T = e_soft_1. Additional logits to softmax, T = e_soft_2)\n",
        "e_soft_1 = 0.8  # @param {type:\"number\"}\n",
        "e_soft_2 = 1.0  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Learning rate for pre-stage (warm-up)\n",
        "learning_rate_pre = 0.1  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Learning rate for soft to hard stages\n",
        "learning_rate = 0.1  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Select interaction distance cutoff and number of inter/intra contacts\n",
        "# @markdown e.g. for metal, change `num_inter_contacts` based on coordination number\n",
        "\n",
        "inter_chain_cutoff = 20  # @param {type:\"integer\"}\n",
        "intra_chain_cutoff = 14  # @param {type:\"integer\"}\n",
        "num_inter_contacts = 2  # @param {type:\"integer\"}\n",
        "num_intra_contacts = 2  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Select helix loss\n",
        "helix_loss_max = 0.0  # @param {type:\"number\"}\n",
        "helix_loss_min = -0.3  # @param {type:\"number\"}\n",
        "\n",
        "# === Default values ===\n",
        "default_params = {\n",
        "    'mask_ligand': True,\n",
        "    'optimize_contact_per_binder_pos': False,\n",
        "    'distogram_only': True,\n",
        "    'design_algorithm': \"3stages\",\n",
        "    'e_soft': 0.8,\n",
        "    'e_soft_1': 0.8,\n",
        "    'e_soft_2': 1.0,\n",
        "    'inter_chain_cutoff': 20,\n",
        "    'intra_chain_cutoff': 14,\n",
        "    'num_inter_contacts': 2,\n",
        "    'num_intra_contacts': 2,\n",
        "    'learning_rate_pre': 0.1,\n",
        "    'learning_rate': 0.1,\n",
        "    'helix_loss_max': 0.0,\n",
        "    'helix_loss_min': -0.3\n",
        "}\n",
        "\n",
        "if not use_default_config:\n",
        "    # Collect current user-specified parameters\n",
        "    current_params = {\n",
        "        'mask_ligand': mask_ligand,\n",
        "        'optimize_contact_per_binder_pos': optimize_contact_per_binder_pos,\n",
        "        'distogram_only': distogram_only,\n",
        "        'design_algorithm': design_algorithm,\n",
        "        'e_soft': e_soft,\n",
        "        'e_soft_1': e_soft_1,\n",
        "        'e_soft_2': e_soft_2,\n",
        "        'inter_chain_cutoff': inter_chain_cutoff,\n",
        "        'intra_chain_cutoff': intra_chain_cutoff,\n",
        "        'num_inter_contacts': num_inter_contacts,\n",
        "        'num_intra_contacts': num_intra_contacts,\n",
        "        'learning_rate_pre': learning_rate_pre,\n",
        "        'learning_rate': learning_rate,\n",
        "        'helix_loss_max': helix_loss_max,\n",
        "        'helix_loss_min': helix_loss_min\n",
        "    }\n",
        "\n",
        "    # Update only changed parameters\n",
        "    updated_keys = []\n",
        "    for key, val in current_params.items():\n",
        "        if val != default_params[key]:\n",
        "            config[key] = val\n",
        "            updated_keys.append(key)\n",
        "\n",
        "    if updated_keys:\n",
        "        print(f\"âœ… Updated config parameters: {', '.join(updated_keys)}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ No config parameters updated; all match defaults.\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ Using default config; no updates applied.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gioG6Gn3uIBX",
        "outputId": "43d91d3b-b423-4de9-85ee-3f6f4da156c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ğŸ”§ ===========================================\n",
            "  ğŸ“¦ Current Config Settings\n",
            "  ğŸ”§ ===========================================\n",
            "  ğŸ·ï¸ binder_chain                   : A          ğŸ·ï¸ design_algorithm               : 3stages\n",
            "  ğŸ·ï¸ disconnect_feats               : True       ğŸ·ï¸ disconnect_pairformer          : False\n",
            "  ğŸ·ï¸ distogram_only                 : True       ğŸ·ï¸ e_soft                         : 0.8\n",
            "  ğŸ·ï¸ e_soft_1                       : 0.8        ğŸ·ï¸ e_soft_2                       : 1.0\n",
            "  ğŸ·ï¸ hard_iteration                 : 5          ğŸ·ï¸ helix_loss_max                 : -0.0\n",
            "  ğŸ·ï¸ helix_loss_min                 : -0.3       ğŸ·ï¸ increasing_contact_over_itr    : False\n",
            "  ğŸ·ï¸ inter_chain_cutoff             : 20.0       ğŸ·ï¸ intra_chain_cutoff             : 14.0\n",
            "  ğŸ·ï¸ learning_rate                  : 0.1        ğŸ·ï¸ learning_rate_pre              : 0.2\n",
            "  ğŸ·ï¸ length_max                     : 300        ğŸ·ï¸ length_min                     : 250\n",
            "  ğŸ·ï¸ mask_ligand                    : True       ğŸ·ï¸ msa_max_seqs                   : 4096\n",
            "  ğŸ·ï¸ non_protein_target             : True       ğŸ·ï¸ num_inter_contacts             : 1\n",
            "  ğŸ·ï¸ num_intra_contacts             : 2          ğŸ·ï¸ optimize_contact_per_binder_pos: False\n",
            "  ğŸ·ï¸ optimizer_type                 : SGD        ğŸ·ï¸ pocket_conditioning            : False\n",
            "  ğŸ·ï¸ pre_iteration                  : 30         ğŸ·ï¸ semi_greedy_steps              : 2\n",
            "  ğŸ·ï¸ set_train                      : True       ğŸ·ï¸ soft_iteration                 : 75\n",
            "  ğŸ·ï¸ soft_iteration_1               : 50         ğŸ·ï¸ soft_iteration_2               : 50\n",
            "  ğŸ·ï¸ temp_iteration                 : 45         ğŸ·ï¸ use_temp                       : True\n",
            "  ğŸ·ï¸ recycling_steps                : 0          ğŸ·ï¸ noise_scaling                  : 0.1\n",
            "  ğŸ”§ ===========================================\n"
          ]
        }
      ],
      "source": [
        "#@title ğŸ“‹ Show Config\n",
        "\n",
        "items = list(config.items())\n",
        "max_key_len = max(len(key) for key, _ in items)\n",
        "max_val_len = max(len(str(val)) for _, val in items)\n",
        "\n",
        "# Print header\n",
        "print(\"  ğŸ”§ \" + \"=\" * (max_key_len + max_val_len + 5))\n",
        "print(\"  ğŸ“¦ Current Config Settings\")\n",
        "print(\"  ğŸ”§ \" + \"=\" * (max_key_len + max_val_len + 5))\n",
        "\n",
        "# Print items in two columns\n",
        "for i in range(0, len(items), 2):\n",
        "    key1, value1 = items[i]\n",
        "    if i + 1 < len(items):\n",
        "        key2, value2 = items[i + 1]\n",
        "        print(f\"  ğŸ·ï¸ {key1:<{max_key_len}}: {str(value1):<{max_val_len}}    \"\n",
        "              f\"ğŸ·ï¸ {key2:<{max_key_len}}: {value2}\")\n",
        "    else:\n",
        "        print(f\"  ğŸ·ï¸ {key1:<{max_key_len}}: {value1}\")\n",
        "\n",
        "print(\"  ğŸ”§ \" + \"=\" * (max_key_len + max_val_len + 5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "sV6KweZ_z6dP"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ”„ Design Iterations Setting\n",
        "# @markdown ---\n",
        "# @markdown Number of pre-iterations (warm-up stage)\n",
        "pre_iteration = 30  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Number of Logits â†’ Softmax iterations\n",
        "soft_iteration = 75  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Number of Softmax (high T) â†’ Softmax (low T) iterations\n",
        "temp_iteration = 45  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Number of one-hot encoded iterations\n",
        "hard_iteration = 5  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Number of MCMC mutation (semi-greedy) steps\n",
        "semi_greedy_steps = 2  # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown Optional (for 3stages_extra algorithm only)\n",
        "soft_iteration_1 = 50  # @param {type:\"integer\"}\n",
        "soft_iteration_2 = 50  # @param {type:\"integer\"}\n",
        "\n",
        "# Apply settings based on the chosen design algorithm\n",
        "if design_algorithm == '3stages':\n",
        "    config['soft_iteration'] = soft_iteration\n",
        "elif design_algorithm == '3stages_extra':\n",
        "    config['soft_iteration_1'] = soft_iteration_1\n",
        "    config['soft_iteration_2'] = soft_iteration_2\n",
        "\n",
        "config['pre_iteration'] = pre_iteration\n",
        "config['temp_iteration'] = temp_iteration\n",
        "config['hard_iteration'] = hard_iteration\n",
        "config['semi_greedy_steps'] = semi_greedy_steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "4ue1_6RUCnwZ"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ”¥ Design Loss Setting\n",
        "# @markdown ---\n",
        "# @markdown Contact loss within protein (binder) chain\n",
        "con_loss = 1  # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Inter contact loss between protein and target\n",
        "i_con_loss = 1  # @param {type:\"number\"}\n",
        "\n",
        "plddt_loss = 0.1  # @param {type:\"number\"}\n",
        "\n",
        "pae_loss = 0.4  # @param {type:\"number\"}\n",
        "\n",
        "i_pae_loss = 0.1  # @param {type:\"number\"}\n",
        "\n",
        "rg_loss = 0.0  # @param {type:\"number\"}\n",
        "\n",
        "loss_scales = {\n",
        "    'con_loss': con_loss,\n",
        "    'i_con_loss': i_con_loss,\n",
        "    'plddt_loss': plddt_loss,\n",
        "    'pae_loss': pae_loss,\n",
        "    'i_pae_loss': i_pae_loss,\n",
        "    'rg_loss': rg_loss,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2GMy7MxL4Kj1",
        "outputId": "24a7ccb7-4541-4985-e002-cc7eeb6e98a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pre-run warm up\n",
            "set in train mode\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/./BoltzDesign1/boltzdesign/boltzdesign_utils.py:597: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return grad * torch.sqrt(torch.tensor(eff_L)) / (gn + 1e-7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.93, ['con_loss:5.17', 'helix_loss:0.84']\n",
            "Epoch 1: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.56, ['con_loss:4.91', 'helix_loss:1.22']\n",
            "Epoch 2: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.78, ['con_loss:5.06', 'helix_loss:0.97']\n",
            "Epoch 3: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.63, ['con_loss:4.94', 'helix_loss:1.08']\n",
            "Epoch 4: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.59, ['con_loss:5.07', 'helix_loss:1.72']\n",
            "Epoch 5: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.63, ['con_loss:4.94', 'helix_loss:1.10']\n",
            "Epoch 6: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.60, ['con_loss:5.13', 'helix_loss:1.88']\n",
            "Epoch 7: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.64, ['con_loss:4.86', 'helix_loss:0.80']\n",
            "Epoch 8: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.72, ['con_loss:4.95', 'helix_loss:0.82']\n",
            "Epoch 9: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.58, ['con_loss:4.87', 'helix_loss:1.02']\n",
            "Epoch 10: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.19, ['con_loss:4.79', 'helix_loss:2.10']\n",
            "Epoch 11: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 5.52, ['con_loss:5.67', 'helix_loss:0.50']\n",
            "Epoch 12: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.51, ['con_loss:5.03', 'helix_loss:1.84']\n",
            "Epoch 13: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.44, ['con_loss:4.92', 'helix_loss:1.69']\n",
            "Epoch 14: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.35, ['con_loss:4.88', 'helix_loss:1.84']\n",
            "Epoch 15: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 4.13, ['con_loss:4.69', 'helix_loss:1.96']\n",
            "Epoch 16: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 3.70, ['con_loss:4.35', 'helix_loss:2.31']\n",
            "Epoch 17: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 2.78, ['con_loss:3.62', 'helix_loss:2.95']\n",
            "Epoch 18: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 2.45, ['con_loss:3.43', 'helix_loss:3.45']\n",
            "Epoch 19: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 2.00, ['con_loss:3.12', 'helix_loss:3.93']\n",
            "Epoch 20: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 2.21, ['con_loss:3.27', 'helix_loss:3.72']\n",
            "Epoch 21: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 1.20, ['con_loss:2.61', 'helix_loss:4.97']\n",
            "Epoch 22: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 0.80, ['con_loss:2.38', 'helix_loss:5.59']\n",
            "Epoch 23: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 1.22, ['con_loss:2.64', 'helix_loss:5.01']\n",
            "Epoch 24: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 0.58, ['con_loss:2.27', 'helix_loss:5.96']\n",
            "Epoch 25: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 0.53, ['con_loss:2.23', 'helix_loss:5.98']\n",
            "Epoch 26: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 0.38, ['con_loss:2.14', 'helix_loss:6.22']\n",
            "Epoch 27: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 0.25, ['con_loss:2.08', 'helix_loss:6.46']\n",
            "Epoch 28: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 0.19, ['con_loss:2.08', 'helix_loss:6.67']\n",
            "Epoch 29: lr: 0.200, soft: 1.00, hard: 0.00, temp: 1.00, total loss: 0.20, ['con_loss:2.07', 'helix_loss:6.59']\n",
            "warm up done\n",
            "set in train mode\n",
            "----------------------------------------------------------------------------------------------------\n",
            "logits to softmax(T=0.8)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch 0: lr: 0.100, soft: 0.00, hard: 0.00, temp: 1.00, total loss: 3.98, ['con_loss:2.08', 'i_con_loss:3.77', 'helix_loss:6.60']\n",
            "Epoch 1: lr: 0.100, soft: 0.01, hard: 0.00, temp: 1.00, total loss: 3.88, ['con_loss:2.15', 'i_con_loss:3.61', 'helix_loss:6.62']\n",
            "Epoch 2: lr: 0.100, soft: 0.02, hard: 0.00, temp: 1.00, total loss: 3.57, ['con_loss:2.06', 'i_con_loss:3.41', 'helix_loss:6.69']\n",
            "Epoch 3: lr: 0.100, soft: 0.03, hard: 0.00, temp: 1.00, total loss: 4.00, ['con_loss:2.12', 'i_con_loss:3.77', 'helix_loss:6.65']\n",
            "Epoch 4: lr: 0.100, soft: 0.04, hard: 0.00, temp: 1.00, total loss: 3.65, ['con_loss:2.21', 'i_con_loss:3.19', 'helix_loss:6.15']\n",
            "Epoch 5: lr: 0.100, soft: 0.05, hard: 0.00, temp: 1.00, total loss: 2.74, ['con_loss:2.05', 'i_con_loss:2.61', 'helix_loss:6.76']\n",
            "Epoch 6: lr: 0.100, soft: 0.06, hard: 0.00, temp: 1.00, total loss: 3.37, ['con_loss:2.09', 'i_con_loss:3.19', 'helix_loss:6.70']\n",
            "Epoch 7: lr: 0.100, soft: 0.07, hard: 0.00, temp: 1.00, total loss: 2.50, ['con_loss:2.09', 'i_con_loss:2.35', 'helix_loss:6.83']\n",
            "Epoch 8: lr: 0.100, soft: 0.09, hard: 0.00, temp: 1.00, total loss: 2.41, ['con_loss:2.08', 'i_con_loss:2.27', 'helix_loss:6.81']\n",
            "Epoch 9: lr: 0.100, soft: 0.10, hard: 0.00, temp: 1.00, total loss: 2.22, ['con_loss:2.02', 'i_con_loss:2.17', 'helix_loss:6.92']\n",
            "Epoch 10: lr: 0.100, soft: 0.11, hard: 0.00, temp: 1.00, total loss: 2.55, ['con_loss:1.99', 'i_con_loss:2.51', 'helix_loss:6.87']\n",
            "Epoch 11: lr: 0.100, soft: 0.12, hard: 0.00, temp: 1.00, total loss: 2.12, ['con_loss:1.97', 'i_con_loss:2.08', 'helix_loss:6.84']\n",
            "Epoch 12: lr: 0.100, soft: 0.13, hard: 0.00, temp: 1.00, total loss: 1.86, ['con_loss:1.88', 'i_con_loss:2.04', 'helix_loss:7.25']\n",
            "Epoch 13: lr: 0.100, soft: 0.14, hard: 0.00, temp: 1.00, total loss: 2.13, ['con_loss:2.03', 'i_con_loss:2.01', 'helix_loss:6.73']\n",
            "Epoch 14: lr: 0.100, soft: 0.15, hard: 0.00, temp: 1.00, total loss: 1.77, ['con_loss:1.87', 'i_con_loss:1.95', 'helix_loss:7.23']\n",
            "Epoch 15: lr: 0.100, soft: 0.16, hard: 0.00, temp: 1.00, total loss: 1.67, ['con_loss:1.85', 'i_con_loss:1.90', 'helix_loss:7.35']\n",
            "Epoch 16: lr: 0.100, soft: 0.17, hard: 0.00, temp: 1.00, total loss: 1.41, ['con_loss:1.78', 'i_con_loss:1.78', 'helix_loss:7.57']\n",
            "Epoch 17: lr: 0.100, soft: 0.18, hard: 0.00, temp: 1.00, total loss: 1.41, ['con_loss:1.79', 'i_con_loss:1.73', 'helix_loss:7.45']\n",
            "Epoch 18: lr: 0.100, soft: 0.19, hard: 0.00, temp: 1.00, total loss: 1.19, ['con_loss:1.73', 'i_con_loss:1.65', 'helix_loss:7.72']\n",
            "Epoch 19: lr: 0.100, soft: 0.20, hard: 0.00, temp: 1.00, total loss: 1.00, ['con_loss:1.68', 'i_con_loss:1.56', 'helix_loss:7.88']\n",
            "Epoch 20: lr: 0.100, soft: 0.21, hard: 0.00, temp: 1.00, total loss: 1.09, ['con_loss:1.65', 'i_con_loss:1.72', 'helix_loss:8.03']\n",
            "Epoch 21: lr: 0.100, soft: 0.22, hard: 0.00, temp: 1.00, total loss: 0.84, ['con_loss:1.57', 'i_con_loss:1.59', 'helix_loss:8.18']\n",
            "Epoch 22: lr: 0.100, soft: 0.23, hard: 0.00, temp: 1.00, total loss: 0.97, ['con_loss:1.61', 'i_con_loss:1.67', 'helix_loss:8.13']\n",
            "Epoch 23: lr: 0.100, soft: 0.25, hard: 0.00, temp: 1.00, total loss: 0.69, ['con_loss:1.55', 'i_con_loss:1.49', 'helix_loss:8.28']\n",
            "Epoch 24: lr: 0.100, soft: 0.26, hard: 0.00, temp: 1.00, total loss: 0.58, ['con_loss:1.48', 'i_con_loss:1.49', 'helix_loss:8.42']\n",
            "Epoch 25: lr: 0.100, soft: 0.27, hard: 0.00, temp: 1.00, total loss: 0.46, ['con_loss:1.44', 'i_con_loss:1.45', 'helix_loss:8.59']\n",
            "Epoch 26: lr: 0.100, soft: 0.28, hard: 0.00, temp: 1.00, total loss: 1.58, ['con_loss:1.73', 'i_con_loss:2.01', 'helix_loss:7.60']\n",
            "Epoch 27: lr: 0.100, soft: 0.29, hard: 0.00, temp: 1.00, total loss: 0.52, ['con_loss:1.48', 'i_con_loss:1.44', 'helix_loss:8.45']\n",
            "Epoch 28: lr: 0.100, soft: 0.30, hard: 0.00, temp: 1.00, total loss: 0.41, ['con_loss:1.44', 'i_con_loss:1.43', 'helix_loss:8.67']\n",
            "Epoch 29: lr: 0.100, soft: 0.31, hard: 0.00, temp: 1.00, total loss: 0.35, ['con_loss:1.41', 'i_con_loss:1.46', 'helix_loss:8.88']\n",
            "Epoch 30: lr: 0.100, soft: 0.32, hard: 0.00, temp: 1.00, total loss: 0.23, ['con_loss:1.38', 'i_con_loss:1.36', 'helix_loss:8.87']\n",
            "Epoch 31: lr: 0.100, soft: 0.33, hard: 0.00, temp: 1.00, total loss: 0.28, ['con_loss:1.37', 'i_con_loss:1.41', 'helix_loss:8.84']\n",
            "Epoch 32: lr: 0.100, soft: 0.34, hard: 0.00, temp: 1.00, total loss: 0.19, ['con_loss:1.36', 'i_con_loss:1.37', 'helix_loss:8.95']\n",
            "Epoch 33: lr: 0.100, soft: 0.35, hard: 0.00, temp: 1.00, total loss: 0.46, ['con_loss:1.42', 'i_con_loss:1.50', 'helix_loss:8.71']\n",
            "Epoch 34: lr: 0.100, soft: 0.36, hard: 0.00, temp: 1.00, total loss: 0.12, ['con_loss:1.31', 'i_con_loss:1.37', 'helix_loss:9.05']\n",
            "Epoch 35: lr: 0.100, soft: 0.37, hard: 0.00, temp: 1.00, total loss: 0.11, ['con_loss:1.31', 'i_con_loss:1.38', 'helix_loss:9.10']\n",
            "Epoch 36: lr: 0.100, soft: 0.38, hard: 0.00, temp: 1.00, total loss: 0.20, ['con_loss:1.33', 'i_con_loss:1.40', 'helix_loss:8.92']\n",
            "Epoch 37: lr: 0.100, soft: 0.39, hard: 0.00, temp: 1.00, total loss: 0.13, ['con_loss:1.30', 'i_con_loss:1.41', 'helix_loss:9.11']\n",
            "Epoch 38: lr: 0.100, soft: 0.41, hard: 0.00, temp: 1.00, total loss: 0.03, ['con_loss:1.28', 'i_con_loss:1.35', 'helix_loss:9.19']\n",
            "Epoch 39: lr: 0.100, soft: 0.42, hard: 0.00, temp: 1.00, total loss: 0.08, ['con_loss:1.30', 'i_con_loss:1.36', 'helix_loss:9.07']\n",
            "Epoch 40: lr: 0.100, soft: 0.43, hard: 0.00, temp: 1.00, total loss: 0.03, ['con_loss:1.28', 'i_con_loss:1.36', 'helix_loss:9.21']\n",
            "Epoch 41: lr: 0.100, soft: 0.44, hard: 0.00, temp: 1.00, total loss: 0.07, ['con_loss:1.26', 'i_con_loss:1.44', 'helix_loss:9.29']\n",
            "Epoch 42: lr: 0.100, soft: 0.45, hard: 0.00, temp: 1.00, total loss: -0.08, ['con_loss:1.25', 'i_con_loss:1.28', 'helix_loss:9.21']\n",
            "Epoch 43: lr: 0.100, soft: 0.46, hard: 0.00, temp: 1.00, total loss: -0.09, ['con_loss:1.28', 'i_con_loss:1.28', 'helix_loss:9.33']\n",
            "Epoch 44: lr: 0.100, soft: 0.47, hard: 0.00, temp: 1.00, total loss: -0.08, ['con_loss:1.22', 'i_con_loss:1.34', 'helix_loss:9.34']\n",
            "Epoch 45: lr: 0.100, soft: 0.48, hard: 0.00, temp: 1.00, total loss: -0.18, ['con_loss:1.20', 'i_con_loss:1.31', 'helix_loss:9.50']\n",
            "Epoch 46: lr: 0.100, soft: 0.49, hard: 0.00, temp: 1.00, total loss: -0.20, ['con_loss:1.20', 'i_con_loss:1.27', 'helix_loss:9.43']\n",
            "Epoch 47: lr: 0.100, soft: 0.50, hard: 0.00, temp: 1.00, total loss: -0.13, ['con_loss:1.22', 'i_con_loss:1.38', 'helix_loss:9.59']\n",
            "Epoch 48: lr: 0.100, soft: 0.51, hard: 0.00, temp: 1.00, total loss: -0.24, ['con_loss:1.18', 'i_con_loss:1.30', 'helix_loss:9.59']\n",
            "Epoch 49: lr: 0.100, soft: 0.52, hard: 0.00, temp: 1.00, total loss: -0.14, ['con_loss:1.22', 'i_con_loss:1.33', 'helix_loss:9.46']\n",
            "Epoch 50: lr: 0.100, soft: 0.53, hard: 0.00, temp: 1.00, total loss: -0.24, ['con_loss:1.17', 'i_con_loss:1.30', 'helix_loss:9.55']\n",
            "Epoch 51: lr: 0.100, soft: 0.54, hard: 0.00, temp: 1.00, total loss: -0.39, ['con_loss:1.14', 'i_con_loss:1.23', 'helix_loss:9.72']\n",
            "Epoch 52: lr: 0.100, soft: 0.55, hard: 0.00, temp: 1.00, total loss: -0.30, ['con_loss:1.17', 'i_con_loss:1.27', 'helix_loss:9.67']\n",
            "Epoch 53: lr: 0.100, soft: 0.57, hard: 0.00, temp: 1.00, total loss: -0.33, ['con_loss:1.16', 'i_con_loss:1.26', 'helix_loss:9.71']\n",
            "Epoch 54: lr: 0.100, soft: 0.58, hard: 0.00, temp: 1.00, total loss: -0.28, ['con_loss:1.15', 'i_con_loss:1.32', 'helix_loss:9.69']\n",
            "Epoch 55: lr: 0.100, soft: 0.59, hard: 0.00, temp: 1.00, total loss: -0.19, ['con_loss:1.20', 'i_con_loss:1.33', 'helix_loss:9.59']\n",
            "Epoch 56: lr: 0.100, soft: 0.60, hard: 0.00, temp: 1.00, total loss: -0.38, ['con_loss:1.15', 'i_con_loss:1.21', 'helix_loss:9.68']\n",
            "Epoch 57: lr: 0.100, soft: 0.61, hard: 0.00, temp: 1.00, total loss: -0.26, ['con_loss:1.16', 'i_con_loss:1.31', 'helix_loss:9.64']\n",
            "Epoch 58: lr: 0.100, soft: 0.62, hard: 0.00, temp: 1.00, total loss: -0.38, ['con_loss:1.14', 'i_con_loss:1.26', 'helix_loss:9.79']\n",
            "Epoch 59: lr: 0.100, soft: 0.63, hard: 0.00, temp: 1.00, total loss: -0.34, ['con_loss:1.15', 'i_con_loss:1.27', 'helix_loss:9.70']\n",
            "Epoch 60: lr: 0.100, soft: 0.64, hard: 0.00, temp: 1.00, total loss: -0.27, ['con_loss:1.18', 'i_con_loss:1.28', 'helix_loss:9.62']\n",
            "Epoch 61: lr: 0.100, soft: 0.65, hard: 0.00, temp: 1.00, total loss: -0.38, ['con_loss:1.15', 'i_con_loss:1.24', 'helix_loss:9.76']\n",
            "Epoch 62: lr: 0.100, soft: 0.66, hard: 0.00, temp: 1.00, total loss: -0.40, ['con_loss:1.15', 'i_con_loss:1.19', 'helix_loss:9.67']\n",
            "Epoch 63: lr: 0.100, soft: 0.67, hard: 0.00, temp: 1.00, total loss: -0.40, ['con_loss:1.13', 'i_con_loss:1.26', 'helix_loss:9.84']\n",
            "Epoch 64: lr: 0.100, soft: 0.68, hard: 0.00, temp: 1.00, total loss: -0.31, ['con_loss:1.14', 'i_con_loss:1.32', 'helix_loss:9.79']\n",
            "Epoch 65: lr: 0.100, soft: 0.69, hard: 0.00, temp: 1.00, total loss: -0.36, ['con_loss:1.13', 'i_con_loss:1.28', 'helix_loss:9.75']\n",
            "Epoch 66: lr: 0.100, soft: 0.70, hard: 0.00, temp: 1.00, total loss: -0.39, ['con_loss:1.14', 'i_con_loss:1.23', 'helix_loss:9.71']\n",
            "Epoch 67: lr: 0.100, soft: 0.71, hard: 0.00, temp: 1.00, total loss: -0.36, ['con_loss:1.15', 'i_con_loss:1.26', 'helix_loss:9.77']\n",
            "Epoch 68: lr: 0.100, soft: 0.73, hard: 0.00, temp: 1.00, total loss: -0.42, ['con_loss:1.15', 'i_con_loss:1.20', 'helix_loss:9.76']\n"
          ]
        }
      ],
      "source": [
        "#@title Ready to Run! ğŸš€\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
        "\n",
        "num_workers = 0  #@param {type:\"integer\"}\n",
        "show_animation = True  #@param {type:\"boolean\"}\n",
        "# @markdown Saves the design trajectory at every iteration. âš  **Note:** If you run with `distogram_only` mode, it does not generate coordinates â€” so enabling `save_trajectory` forces the model to predict coordinates every iteration, which requires more time.\n",
        "save_trajectory = False  #@param {type:\"boolean\"}\n",
        "# @markdown Keep this as False in Colab\n",
        "redo_boltz_predict = False  #@param {type:\"boolean\"}\n",
        "boltz_path = shutil.which(\"boltz\")\n",
        "\n",
        "run_boltz_design(\n",
        "    boltz_path=boltz_path,\n",
        "    main_dir=main_dir,\n",
        "    yaml_dir=os.path.dirname(yaml_dir),\n",
        "    boltz_model=boltz_model,\n",
        "    ccd_path=ccd_path,\n",
        "    design_samples=design_samples,\n",
        "    version_name=version_name,\n",
        "    config=config,\n",
        "    loss_scales=loss_scales,\n",
        "    num_workers=num_workers,  # Number of worker processes\n",
        "    show_animation=show_animation,      # Show visual animation\n",
        "    save_trajectory=save_trajectory,     # Save full trajectory + coordinates\n",
        "    redo_boltz_predict=redo_boltz_predict,  # Given final designs, repredict with the boltz predict command\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "pEn85Xnu43oZ",
        "outputId": "e498996b-1e1c-4a4f-96fb-6338f8a98521"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3240472526>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title ğŸ“Š Design Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'results_final'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rmsd_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "#@title ğŸ“Š Design Results\n",
        "df = pd.read_csv(os.path.join(main_dir, version_name, 'results_final', 'rmsd_results.csv'))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9CFeP774Ici"
      },
      "source": [
        "##3. Run LigandMPNN for redesign"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLOajpp7v_EV",
        "outputId": "d795b4fd-318b-4d02-e96d-78b6c45be9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Config updated and saved.\n"
          ]
        }
      ],
      "source": [
        "#@title Update LigandMPNN config file\n",
        "yaml_path = \"/content/BoltzDesign1/LigandMPNN/run_ligandmpnn_logits_config.yaml\"\n",
        "cwd = \"/content/BoltzDesign1\"\n",
        "with open(yaml_path, \"r\") as f:\n",
        "    mpnn_config = yaml.safe_load(f)\n",
        "for key, value in mpnn_config.items():\n",
        "    if isinstance(value, str) and \"${CWD}\" in value:\n",
        "        mpnn_config[key] = value.replace(\"${CWD}\", cwd)\n",
        "assert Path(mpnn_config[\"checkpoint_soluble_mpnn\"]).exists(), \"Checkpoint file not found!\"\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    yaml.dump(mpnn_config, f, default_flow_style=False)\n",
        "print(\"âœ… Config updated and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N6FJGWXVASqy"
      },
      "outputs": [],
      "source": [
        "#@title Set the interface cutoff for redesign and run LigandMPNN\n",
        "#@markdown For LigandMPNN redesign, specify number of designs per PDB\n",
        "num_designs = 2 #@param {type:\"integer\"}\n",
        "#@markdown Cutoff distance in Angstroms between target and binder atoms to define interface residues (default = 4 Ã…). If set into 0Ã…, fully redesign the sequence with LigandMPNN\n",
        "cutoff = 4 #@param {type:\"integer\"}\n",
        "#@markdown Cutoff iPTM for selecting proteins for redesign from the initial BoltzDesign.\n",
        "i_ptm_cutoff = 0.5 #@param {type:\"number\"}\n",
        "#@markdown For protein targets, enter target chain IDs (optional). If not specified, all chains except binder will be considered targets\n",
        "target_ids = \"\" #@param  {type:\"string\"}\n",
        "target_ids = [str(x.strip()) for x in target_ids.split(\",\")] if target_ids else None\n",
        "boltzdesign_dir = main_dir + '/'+   version_name+'/results_final'\n",
        "pdb_save_dir = main_dir +   '/'+ version_name+'/pdb'\n",
        "ligandmpnn_dir = main_dir + '/'+ version_name+'/ligandmpnn_cutoff'\n",
        "ligandmpnn_config= '/content/BoltzDesign1/LigandMPNN/run_ligandmpnn_logits_config.yaml'\n",
        "os.makedirs(ligandmpnn_dir, exist_ok=True)\n",
        "convert_cif_files_to_pdb(boltzdesign_dir, pdb_save_dir, high_iptm = True, i_ptm_cutoff=i_ptm_cutoff)\n",
        "run_ligandmpnn_redesign(ligandmpnn_dir, pdb_save_dir, boltz_path,\n",
        "    os.path.dirname(yaml_dir), ligandmpnn_config, top_k=num_designs, cutoff=cutoff, non_protein_target=non_protein_target, binder_chain=binder_id, target_chains='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lP-SR0lM3jr4"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ†ğŸ‰Download highly confident designs\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "from google.colab import files\n",
        "\n",
        "# --- Parameters ---\n",
        "i_ptm_cutoff = 0.5 #@param {type:\"number\"}\n",
        "complex_plddt_cutoff = 0.7 #@param {type:\"number\"}\n",
        "\n",
        "# --- Directories ---\n",
        "ligandmpnn_dir_boltz = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned')\n",
        "yaml_dir_boltz = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned_yaml')\n",
        "high_iptm_designs_dir = os.path.join(ligandmpnn_dir, '01_lmpnn_redesigned_high_iptm')\n",
        "\n",
        "high_iptm_designs_dir_yaml = os.path.join(high_iptm_designs_dir, 'yaml')\n",
        "high_iptm_designs_dir_cif = os.path.join(high_iptm_designs_dir, 'cif')\n",
        "\n",
        "# --- Create output directories ---\n",
        "os.makedirs(high_iptm_designs_dir_yaml, exist_ok=True)\n",
        "os.makedirs(high_iptm_designs_dir_cif, exist_ok=True)\n",
        "\n",
        "copied_any = False\n",
        "\n",
        "# --- Process designs ---\n",
        "for root in os.listdir(ligandmpnn_dir_boltz):\n",
        "    root_path = os.path.join(ligandmpnn_dir_boltz, root, 'predictions')\n",
        "    if not os.path.isdir(root_path):\n",
        "        continue\n",
        "\n",
        "    for subdir in os.listdir(root_path):\n",
        "        json_path = os.path.join(root_path, subdir, f'confidence_{subdir}_model_0.json')\n",
        "        yaml_path = os.path.join(yaml_dir_boltz, f'{subdir}.yaml')\n",
        "        cif_path = os.path.join(ligandmpnn_dir_boltz, f'boltz_results_{subdir}', 'predictions', subdir, f'{subdir}_model_0.cif')\n",
        "\n",
        "        try:\n",
        "            with open(json_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            design_name = json_path.split('/')[-2]\n",
        "            length = int(subdir[subdir.find('length') + 6:subdir.find('_model')])\n",
        "            iptm = data.get('iptm', 0)\n",
        "            complex_plddt = data.get('complex_plddt', 0)\n",
        "\n",
        "            print(f\"{design_name} length: {length} complex_plddt: {complex_plddt:.2f} iptm: {iptm:.2f}\")\n",
        "\n",
        "            if iptm > i_ptm_cutoff and complex_plddt > complex_plddt_cutoff:\n",
        "                shutil.copy(yaml_path, os.path.join(high_iptm_designs_dir_yaml, f'{subdir}.yaml'))\n",
        "                shutil.copy(cif_path, os.path.join(high_iptm_designs_dir_cif, f'{subdir}.cif'))\n",
        "                print(f\"âœ… {design_name} copied\")\n",
        "                copied_any = True\n",
        "\n",
        "        except (KeyError, FileNotFoundError, json.JSONDecodeError) as e:\n",
        "            print(f\"âš ï¸ Skipping {subdir}: {e}\")\n",
        "            continue\n",
        "\n",
        "# --- Zip and download if any files were copied ---\n",
        "if copied_any:\n",
        "    zip_filename = os.path.join(ligandmpnn_dir, 'high_confidence_designs.zip')\n",
        "    with ZipFile(zip_filename, 'w') as zipf:\n",
        "        for fname in os.listdir(high_iptm_designs_dir_yaml):\n",
        "            fpath = os.path.join(high_iptm_designs_dir_yaml, fname)\n",
        "            zipf.write(fpath, arcname=os.path.join('yaml', fname))\n",
        "        for fname in os.listdir(high_iptm_designs_dir_cif):\n",
        "            fpath = os.path.join(high_iptm_designs_dir_cif, fname)\n",
        "            zipf.write(fpath, arcname=os.path.join('cif', fname))\n",
        "\n",
        "    print(f\"ğŸ“¦ Zipped results saved to {zip_filename}\")\n",
        "    files.download(zip_filename)\n",
        "else:\n",
        "    print(\"âš ï¸ No high-confidence designs found. Skipping zip and download.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pyi8kEM1mOv"
      },
      "source": [
        "## âœ… Work in progress (currently implementing in a pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8uat10G3k5f"
      },
      "outputs": [],
      "source": [
        "## PyRosetta for proteinâ€“protein interface energy/interaction evaluation\n",
        "print(\"Installing PyRosetta\")\n",
        "os.system(\"pip install pyrosettacolabsetup\")\n",
        "with contextlib.redirect_stdout(io.StringIO()):\n",
        "  import pyrosettacolabsetup\n",
        "  pyrosettacolabsetup.install_pyrosetta(serialization=True, cache_wheel_on_google_drive=False)\n",
        "\n",
        "## Gnina for small-molecule docking score\n",
        "!git clone https://github.com/dkoes/openbabel.git\n",
        "!cd openbabel && mkdir build && cd build && cmake -DWITH_MAEPARSER=OFF -DWITH_COORDGEN=OFF -DPYTHON_BINDINGS=ON -DRUN_SWIG=ON ..&& make && make install\n",
        "!git clone https://github.com/gnina/gnina.git\n",
        "!cd gnina && mkdir build && cd build && cmake .. && make && make install"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}